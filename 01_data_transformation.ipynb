{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transformation Using Snowpark for Python\n",
    "\n",
    "The purpose of this script is to demonstrate simple data transformations on Snowflake objects using Snowpark for Python. The intent is to begin with a Snowflake table containing hourly sales data spanning 27 years and perform the following transformations:\n",
    "\n",
    "- Filter the data to 2005 onwards\n",
    "- Aggregate the number of sales by month and category\n",
    "- Sort the data by month and category\n",
    "- Store the result in a new table in Snowflake "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the InterWorks Snowpark package\n",
    "\n",
    "Before we can begin, we must import the required package from the InterWorks Snowpark package and leverage it to create a Snowflake Snowpark Session object that is connected to our Snowflake environment. Alternatively, you can modify the code to establish a Snowflake Snowpark Session through any method of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Import module to build snowpark sessions\n",
    "from interworks_snowpark.snowpark_session_builder import build_snowpark_session_via_parameters_json as build_snowpark_session\n",
    "\n",
    "## Generate Snowpark session\n",
    "snowpark_session = build_snowpark_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve source table from staging\n",
    "\n",
    "Our source data is contained in the following object: `\"SALES_DB\".\"STAGING\".\"PRODUCT_SALES\"` and is read into a Snowflake dataframe object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_source = snowpark_session.table('\"SALES_DB\".\"STAGING\".\"PRODUCT_SALES\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be quickly queried to confirm the contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "|\"SALE_DATE\"  |\"CATEGORY\"   |\"SUBCATEGORY\"            |\"SALES\"             |\n",
      "----------------------------------------------------------------------------\n",
      "|1995-01-01   |PRO EDITION  |PRO ADMIN                |24.625859817152804  |\n",
      "|1995-01-01   |PRO EDITION  |PRO DEVELOPER            |41.043099695254675  |\n",
      "|1995-01-01   |PRO EDITION  |PRO CONSUMER             |16.417239878101874  |\n",
      "|1995-01-01   |ENTERPRISE   |ENTERPRISE ADMIN         |25.752198519808445  |\n",
      "|1995-01-01   |ENTERPRISE   |ENTERPRISE DEVELOPER     |34.33626469307793   |\n",
      "|1995-01-01   |ENTERPRISE   |ENTERPRISE COLLABORATOR  |17.168132346538965  |\n",
      "|1995-01-01   |ENTERPRISE   |ENTERPRISE CONSUMER      |8.584066173269482   |\n",
      "|1995-01-02   |PRO EDITION  |PRO ADMIN                |5.088506747932085   |\n",
      "|1995-01-02   |PRO EDITION  |PRO DEVELOPER            |8.480844579886808   |\n",
      "|1995-01-02   |PRO EDITION  |PRO CONSUMER             |3.3923378319547237  |\n",
      "----------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_source.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations\n",
    "\n",
    "We are now ready to begin our transformations. Before we can do so, we must import a few functions from the `snowflake.snowpark.functions` module. Most notably, we wish to import `col` as this allows us to target a specific field in a Snowflake dataframe. In addition, we wish to import the native [Snowflake DATE_TRUNC function](https://docs.snowflake.com/en/sql-reference/functions/date_trunc.html) so that we can reduce a timestamp to a year/month, the native [Snowflake YEAR function](https://docs.snowflake.com/en/sql-reference/functions/year.html) so that we can quickly identify and filter by the year of a timestamp, and the native [Snowflake TO_DATE function](https://docs.snowflake.com/en/sql-reference/functions/to_date.html) so that we convert our truncated timestamps into dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.functions import col\n",
    "from snowflake.snowpark.functions import year\n",
    "from snowflake.snowpark.functions import date_trunc\n",
    "from snowflake.snowpark.functions import to_date\n",
    "from snowflake.snowpark.functions import sum as sf_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter the data to 2005 onwards\n",
    "\n",
    "We leverage the `YEAR` function in Snowflake to determine the year for each record, then filter for when this is greater than or equal to 2005."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "|\"SALE_DATE\"  |\"CATEGORY\"   |\"SUBCATEGORY\"            |\"SALES\"             |\n",
      "----------------------------------------------------------------------------\n",
      "|2005-01-01   |PRO EDITION  |PRO ADMIN                |13.499431243680485  |\n",
      "|2005-01-01   |PRO EDITION  |PRO DEVELOPER            |22.499052072800808  |\n",
      "|2005-01-01   |PRO EDITION  |PRO CONSUMER             |8.999620829120323   |\n",
      "|2005-01-01   |ENTERPRISE   |ENTERPRISE ADMIN         |11.302098078867544  |\n",
      "|2005-01-01   |ENTERPRISE   |ENTERPRISE DEVELOPER     |15.069464105156724  |\n",
      "|2005-01-01   |ENTERPRISE   |ENTERPRISE COLLABORATOR  |7.534732052578362   |\n",
      "|2005-01-01   |ENTERPRISE   |ENTERPRISE CONSUMER      |3.767366026289181   |\n",
      "|2005-01-02   |PRO EDITION  |PRO ADMIN                |35.80700202224469   |\n",
      "|2005-01-02   |PRO EDITION  |PRO DEVELOPER            |59.67833670374115   |\n",
      "|2005-01-02   |PRO EDITION  |PRO CONSUMER             |23.87133468149646   |\n",
      "----------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered = df_source.filter(year(col(\"SALE_DATE\")) >= 2005)\n",
    "\n",
    "df_filtered.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate the number of sales by month and category\n",
    "\n",
    "Now that we have our categories, we are ready to group our data with the `groupby` method. Again, note how we leverage `sf_sum` to avoid using the standard Python `sum` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "|\"SALE_MONTH\"  |\"CATEGORY\"   |\"SALES\"  |\n",
      "----------------------------------------\n",
      "|2005-01-01    |PRO EDITION  |2525.0   |\n",
      "|2005-01-01    |ENTERPRISE   |2114.0   |\n",
      "|2005-02-01    |PRO EDITION  |2459.5   |\n",
      "|2005-02-01    |ENTERPRISE   |2109.0   |\n",
      "|2005-03-01    |PRO EDITION  |2364.75  |\n",
      "|2005-03-01    |ENTERPRISE   |2366.0   |\n",
      "|2005-04-01    |PRO EDITION  |2041.5   |\n",
      "|2005-04-01    |ENTERPRISE   |2300.0   |\n",
      "|2005-05-01    |PRO EDITION  |2174.25  |\n",
      "|2005-05-01    |ENTERPRISE   |2569.0   |\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_grouped = df_filtered \\\n",
    "  .group_by(to_date(date_trunc('month', col(\"SALE_DATE\"))), col(\"CATEGORY\")) \\\n",
    "  .agg(sf_sum(col(\"SALES\"))) \\\n",
    "  .select(col(\"TO_DATE(DATE_TRUNC(MONTH, SALE_DATE))\").alias(\"SALE_MONTH\"), col(\"CATEGORY\"), col(\"SUM(SALES)\").alias(\"SALES\"))\n",
    "\n",
    "df_grouped.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort the data\n",
    "\n",
    "Using the `sort()` method, we can simply sort the data by category and month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "|\"SALE_MONTH\"  |\"CATEGORY\"   |\"SALES\"  |\n",
      "----------------------------------------\n",
      "|2005-01-01    |ENTERPRISE   |2114.0   |\n",
      "|2005-01-01    |PRO EDITION  |2525.0   |\n",
      "|2005-02-01    |ENTERPRISE   |2109.0   |\n",
      "|2005-02-01    |PRO EDITION  |2459.5   |\n",
      "|2005-03-01    |ENTERPRISE   |2366.0   |\n",
      "|2005-03-01    |PRO EDITION  |2364.75  |\n",
      "|2005-04-01    |ENTERPRISE   |2300.0   |\n",
      "|2005-04-01    |PRO EDITION  |2041.5   |\n",
      "|2005-05-01    |ENTERPRISE   |2569.0   |\n",
      "|2005-05-01    |PRO EDITION  |2174.25  |\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sorted = df_grouped.sort(col(\"SALE_MONTH\"), col(\"CATEGORY\"))\n",
    "\n",
    "df_sorted.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the result in a new table in Snowflake\n",
    "\n",
    "Finally, we can output the data into a table in Snowflake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted.write.mode(\"overwrite\").save_as_table('\"SALES_DB\".\"CLEAN\".\"PRODUCT_SALES\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Results\n",
    "\n",
    "We can connect directly to our new table in Snowflake to verify the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "|\"SALE_MONTH\"  |\"CATEGORY\"   |\"SALES\"  |\n",
      "----------------------------------------\n",
      "|2005-01-01    |ENTERPRISE   |2114.0   |\n",
      "|2005-01-01    |PRO EDITION  |2525.0   |\n",
      "|2005-02-01    |ENTERPRISE   |2109.0   |\n",
      "|2005-02-01    |PRO EDITION  |2459.5   |\n",
      "|2005-03-01    |ENTERPRISE   |2366.0   |\n",
      "|2005-03-01    |PRO EDITION  |2364.75  |\n",
      "|2005-04-01    |ENTERPRISE   |2300.0   |\n",
      "|2005-04-01    |PRO EDITION  |2041.5   |\n",
      "|2005-05-01    |ENTERPRISE   |2569.0   |\n",
      "|2005-05-01    |PRO EDITION  |2174.25  |\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "snowpark_session.table('\"SALES_DB\".\"CLEAN\".\"PRODUCT_SALES\"').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5abca2f2ea4766feab0d5ed22ebf4aa677d5ebd9a43ee5e630cd7fa0b11fb4d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
