{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Using Snowpark for Python and Auto Arima\n",
    "\n",
    "The purpose of this script is to demonstrate simple data science predictions on Snowflake objects using Snowpark for Python and Auto Arima. The intent is to begin with a Snowflake table containing monthly website sales data spanning multiple categories and create a predictive model to approximate future sales.\n",
    "\n",
    "Our final process will iterate over both categories in the dataset, before combining the results into a single table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the various packages\n",
    "\n",
    "Before we can begin, we must import the required packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import pmdarima\n",
    "import snowflake.snowpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InterWorks Snowpark package\n",
    "\n",
    "We must also import the required package from the InterWorks Snowpark package and leverage it to create a Snowflake Snowpark Session object that is connected to our Snowflake environment. Alternatively, you can modify the code to establish a Snowflake Snowpark Session through any method of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import module to build snowpark sessions\n",
    "from interworks_snowpark.snowpark_session_builder import build_snowpark_session_via_parameters_json as build_snowpark_session\n",
    "\n",
    "## Generate Snowpark session\n",
    "snowpark_session = build_snowpark_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Snowflake Stored Procedure\n",
    "\n",
    "Now that we have run through the above in steps, we can combine it all into a function and convert it into a stored procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create function\n",
    "\n",
    "The first part of creating a Stored Procedure to deploy to Snowflake is to create the function that will become the Stored Procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_auto_arima_predictions(\n",
    "    snowpark_session: snowflake.snowpark.Session\n",
    "  , origin_table: str\n",
    "  , destination_table: str\n",
    ") :\n",
    "\n",
    "  # Retrieve the data from the source table\n",
    "  df_sales_sf = snowpark_session.table(f'\"SALES_DB\".\"CLEAN\".\"{origin_table}\"')\n",
    "\n",
    "  # Convert data into a Pandas dataframe\n",
    "  df_sales = pandas.DataFrame(data=df_sales_sf.collect()) \\\n",
    "    .sort_values(by=[\"SALE_MONTH\",\"CATEGORY\" ], ignore_index=True)\n",
    "\n",
    "  # Convert the data field into a Pandas datetime\n",
    "  df_sales[\"SALE_MONTH\"] = pandas.to_datetime(df_sales[\"SALE_MONTH\"]).dt.tz_localize('UTC')\n",
    "  \n",
    "  # Define prediction horizon of 2 years\n",
    "  pred_periods = 24\n",
    "\n",
    "  # Define final output dataframe\n",
    "  df_final_output = pandas.DataFrame(columns=[\"SALE_MONTH\", \"CATEGORY\", \"SALES\", \"TRAIN_PREDICTION\", \"TEST_PREDICTION\"])\n",
    "\n",
    "  # Iterate through different categories\n",
    "  for category in df_sales[\"CATEGORY\"].unique():\n",
    "\n",
    "    # Define dataframe for current category\n",
    "    df_current_category = df_sales[df_sales[\"CATEGORY\"] == category].reset_index(drop=True)\n",
    "\n",
    "    # Test and train\n",
    "    split_number = df_current_category['SALES'].count() - pred_periods\n",
    "    df_train     = pandas.DataFrame(df_current_category['SALES'][:split_number]).rename(columns={'SALES':'y_train'})\n",
    "    df_test      = pandas.DataFrame(df_current_category['SALES'][split_number:]).rename(columns={'SALES':'y_test' })\n",
    "\n",
    "    # Create Auto Arima model\n",
    "    model_fit = pmdarima.auto_arima(df_train, test='adf', \n",
    "                          max_p=3, max_d=3, max_q=3, \n",
    "                          seasonal=True, m=12,\n",
    "                          max_P=3, max_D=2, max_Q=3,\n",
    "                          trace=True,\n",
    "                          error_action='ignore',  \n",
    "                          suppress_warnings=True, \n",
    "                          stepwise=True)\n",
    "\n",
    "    # Generate in-sample predictions\n",
    "    pred = model_fit.predict_in_sample(dynamic=False) # works only with auto-arima\n",
    "    df_train['y_train_pred'] = pandas.to_numeric(pred)\n",
    "\n",
    "    # Generate predictions on test data\n",
    "    test_pred = model_fit.predict(n_periods=pred_periods, dynamic=False)\n",
    "    df_test['y_test_pred'] = pandas.to_numeric(test_pred)\n",
    "\n",
    "    # Combine test and train prediction values with original\n",
    "    df_combined = pandas.concat([df_current_category, df_train, df_test], axis = 1) \\\n",
    "      .rename(columns={'y_train_pred':'TRAIN_PREDICTION', 'y_test_pred': 'TEST_PREDICTION'}) \\\n",
    "      [[\"SALE_MONTH\", \"CATEGORY\", \"SALES\", \"TRAIN_PREDICTION\", \"TEST_PREDICTION\"]]\n",
    "\n",
    "    # Append combined result to final output\n",
    "    df_final_output = pandas.concat([df_final_output, df_combined], ignore_index = True, sort = False)\n",
    "  \n",
    "  # Write output back to Snowflake\n",
    "  snowpark_session.write_pandas(\n",
    "      df = df_final_output\n",
    "    , table_name = destination_table\n",
    "    , schema = 'MART'\n",
    "    , database = 'SALES_DB'\n",
    "    , auto_create_table = True\n",
    "  )\n",
    "\n",
    "  return 'Complete'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import any required Snowpark objects\n",
    "\n",
    "Our stored procedure only requires the data type `StringType` as all inputs and outputs are strings. We must also import the function to create stored procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.functions import sproc\n",
    "from snowflake.snowpark.types import StringType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the required packages to the session\n",
    "\n",
    "Add required packages into the session creating our stored procedure, so that the stored procedure can leverage them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowpark_session.add_packages('snowflake-snowpark-python', 'pandas', 'pmdarima')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert function into Stored Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.snowpark.stored_procedure.StoredProcedure at 0x1acb411e4c0>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowpark_session.sproc.register(\n",
    "    func = generate_auto_arima_predictions\n",
    "  , return_type = StringType()\n",
    "  , input_types = [StringType(), StringType()]\n",
    "  , is_permanent = True\n",
    "  , name = 'SALES_DB.PROCEDURES.GENERATE_AUTO_ARIMA_FUNCTION'\n",
    "  , replace = True\n",
    "  , stage_location = '@SALES_DB.PROCEDURES.MY_STAGE'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5abca2f2ea4766feab0d5ed22ebf4aa677d5ebd9a43ee5e630cd7fa0b11fb4d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
